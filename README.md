# The Winter is Coming Challenge ğŸŒ¨ï¸

A comprehensive project exploring **Model Steering** techniques on **Stable Diffusion** using **Activation Patching** to inject winter concepts into generated images.

## ğŸ¯ Project Overview

This project demonstrates advanced AI model manipulation techniques by:
- Implementing **activation patching** on Stable Diffusion models
- Creating **steering vectors** to inject seasonal concepts
- Developing **adaptive patching strategies** for different prompt types
- Evaluating results using **CLIP similarity scoring**

## ğŸ—ï¸ Architecture

### Stable Diffusion Components
- **Text Encoder**: Converts text prompts into semantic embeddings
- **U-Net**: Iteratively refines noisy latent representations
- **VAE**: Compresses/decompresses between pixel and latent space

### Model Steering Pipeline
```
Input Prompt â†’ Text Encoder â†’ Activation Patching â†’ U-Net â†’ VAE Decoder â†’ Winter Image
```

## ğŸ“Š Dataset

The project uses `prompts.csv` containing 30 diverse textual prompts:

| Column | Type    | Description                    |
|--------|---------|--------------------------------|
| ID     | Integer | Unique prompt identifier (0â€“29) |
| prompt | String  | Textual scene description      |

## ğŸš€ Key Features

### 1. **NNsight Integration**
- Easy access to model activations and gradients
- Intuitive interface for model intervention
- Real-time activation monitoring

### 2. **Steering Vector Computation**
```python
steering_vector = (positive_activations - negative_activations) / 2
```
- Positive prompts: Winter-related scenes
- Negative prompts: Summer/non-winter scenes
- Calculated across all 23 text encoder layers

### 3. **Adaptive Patching System**
Smart parameter adjustment based on prompt analysis:
- **High Resistance**: Summer/hot weather prompts â†’ Stronger patching
- **Medium Resistance**: Nature/outdoor prompts â†’ Moderate patching  
- **Low Resistance**: Indoor/neutral prompts â†’ Gentle patching

### 4. **CLIP Evaluation**
Quantitative assessment using cosine similarity:
- Winter similarity scoring
- Original prompt fidelity measurement
- Automated parameter optimization

## ğŸ“ˆ Results

### Experimental Findings
- **Best Configuration**: Layers [0, 6, 7, 8] with Îµ = [0.8, 0.5, 1.0, 2.0]
- **Winter Similarity**: 0.2308 (CLIP score)
- **Multi-layer Approach**: Outperforms single-layer modifications
- **17 Automated Experiments**: Revealing optimal configurations

### Performance Metrics
- Successfully generated 30 winter-themed images
- Adaptive patching improved difficult prompts by 40%
- Maintained original prompt fidelity while enhancing winter content

## ğŸ› ï¸ Installation

```bash
# Install required dependencies
pip install --no-deps nnsight
pip install msgspec python-socketio[client]
pip install ftfy
pip install torch torchvision
pip install transformers
pip install matplotlib seaborn
pip install rich
```

## ğŸ”§ Usage

### Basic Image Generation
```python
from nnsight.modeling.diffusion import DiffusionModel

model = DiffusionModel("stabilityai/stable-diffusion-2-1-base", dispatch=True)
prompt = "A beautiful landscape"

with model.generate(prompt, seed=17):
    image = model.output.images[0].save()
```

### Activation Patching
```python
# Extract steering vector
positive_activations = get_MLP_activations("winter landscape")
negative_activations = get_MLP_activations("summer landscape")
steering_vector = (positive_activations - negative_activations) / 2

# Apply patching
layers = [0, 6, 7, 8]
eps_values = [0.8, 0.5, 1.0, 2.0]

with model.generate(prompt, seed=17):
    for i, layer_idx in enumerate(layers):
        component = model.text_encoder.text_model.encoder.layers[layer_idx].mlp
        component.output[0][:] += eps_values[i] * steering_vector[layer_idx]
    image = model.output.images[0].save()
```

### Adaptive Patching
```python
adaptive_system = AdaptivePatching(steering_vector, model, seed=17)
image = adaptive_system.generate_adaptive_image(prompt, verbose=True)
```

## ğŸ“ Project Structure

```
ğŸ“¦ winter-diffusion-challenge/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ““ The_winter_is_coming.ipynb       # Main notebook
â”œâ”€â”€ ğŸ““ converter.ipynb                  # Base64 conversion utilities
â”œâ”€â”€ ğŸ“Š prompts.csv                      # Input prompts dataset
â”œâ”€â”€ ğŸ“Š adaptive_submission.csv          # Final results
â””â”€â”€ ğŸ–¼ï¸ images/                          # Generated image samples
    â”œâ”€â”€ 0.png
    â”œâ”€â”€ 1.png
    â””â”€â”€ ...
```

## ğŸ”¬ Technical Deep Dive

### Activation Interception
```python
with model.generate(prompt, seed=SEED):
    collected_activation = component.output.save()
```

### MLP Layer Targeting
- **Layers 0-8**: Early semantic processing
- **Layers 10-11**: Mid-level concept formation
- **Layers 15-20**: High-level semantic integration

### Steering Vector Mathematics
The steering vector computation follows:
$$\text{Steering Vector} = \frac{1}{|D_{pos}|+|D_{neg}|} \sum_{i}(D_{pos}[i] - D_{neg}[i])$$

## ğŸ“Š Evaluation Metrics

### CLIP Similarity Analysis
- **Winter Similarity**: Measures winter content injection
- **Original Similarity**: Maintains prompt fidelity
- **Comparative Analysis**: Heatmaps and scatter plots

### Visualization Tools
- Parameter performance heatmaps
- Winter vs. original similarity scatter plots
- Activation difference analysis

## ğŸ¨ Sample Results

Generated images successfully demonstrate:
- â„ï¸ Snow and ice effects on landscapes
- ğŸŒ¨ï¸ Winter atmosphere injection
- ğŸ”ï¸ Seasonal transformation of scenes
- ğŸŒ² Winter vegetation and environmental changes

## ğŸ”® Future Enhancements

- [ ] **U-Net Activation Patching**: Explore diffusion process interventions
- [ ] **Dynamic Epsilon Adjustment**: Real-time parameter optimization
- [ ] **Multi-Concept Steering**: Combine multiple seasonal concepts
- [ ] **Advanced CLIP Metrics**: Fine-grained similarity analysis
- [ ] **Temporal Consistency**: Video generation applications

## ğŸ“š References

- [NNsight Documentation](https://nnsight.net/)
- [Stable Diffusion Paper](https://arxiv.org/abs/2112.10752)
- [CLIP: Connecting Text and Images](https://arxiv.org/abs/2103.00020)
- [Activation Patching Techniques](https://arxiv.org/abs/2202.05262)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit pull requests, report issues, or suggest improvements.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Stability AI** for the Stable Diffusion model
- **OpenAI** for CLIP evaluation framework
- **NNsight Team** for the model intervention library
- **Hugging Face** for model hosting and transformers library

---

*Generated with â„ï¸ by The Winter is Coming Challenge*
